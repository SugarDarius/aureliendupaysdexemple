---
title: 'Liveblocks drawing on screen'
publishedAt: '2024-06-24'
summary: 'An experiment with Liveblocks broadcasted events to draw on screen'
category: 'Lab / Open Source'
githubURL: 'https://github.com/SugarDarius/aureliendupaysdexemple/blob/main/components/lab/drawing-on-screen-editor.tsx'
image: '/medias/mdx-content/liveblocks-drawing-on-screen.webp'
---

# An experiment to draw on screen

This experiment comes from my use of Slack Huddle when someone was sharing his screen and we were drawing on it with a pen tool.

I wanted to re-create it using a great collaborative tool to do it.
So I chosen to use [Liveblocks](https://liveblocks.io/) and implement it on my personal website as a Lab ðŸ™‚.

## Why drawing on screen?

Drawing on screen is to me a great feature. It brings value and accessibility to users especially when sharing a screen in an application.
It makes easier to communicate and express yourself when your pointing something present in the shared screen.

From a collaborative standpoint, drawing on screen in real-time brings some great benefits such as:

- Enhanced communication
- Improved collaboration
- Users engagement
- Visual clarity
- Real-time feedback
- Interactive learning
- Memory aid

Having this feature in your product when you let users sharing their screen to each others make the collaborative side more stronger.

## Let's talk about Liveblocks

[Liveblocks](https://liveblocks.io/) is for me a great product providing a complete toolkit to developers to integrate collaborative experiences seamlessly with pace.

Benefits of using **Liveblocks** as a developer are you can integrates with your frontend framework while Liveblocks is managing all the infrastructure and scaling for you.
As a developer deeply believing in frontend cloud it's for me a good match.

Adding **Liveblocks** into your project is very straightforward.
First you need to create an account on the web app and then you install the packages you need in your app.
In my case on my personal website:

```sh
$ npm i @liveblocks/client @liveblocks/react
```

Once you've installed the dependencies and got your public key created on the **Liveblocks** dashboard then you can set up your custom types in your <InlineCode>liveblocks.config.ts</InlineCode>:

```tsx
declare global {
  interface Liveblocks {
    Presence: MyPresence
    RoomEvent: MyRoomEvent
  }
}
```

And setting up your <InlineCode>LiveblocksProvider</InlineCode> in your app:

```tsx
import { LiveblocksProvider } from '@liveblocks/react/suspense'

function MyApp({ children }: { children: React.ReactNode }) {
  return (
    <LiveblocksProvider publicApiKey='your-public-api-key'>
      {children}
    </LiveblocksProvider>
  )
}
```

And we're good to go ðŸš€

## Drawing paths on screen with an svg canvas

Drawing on screen when sharing screen should stay simple and light in my opinion.
So I though that instead of using a <InlineCode>canvas</InlineCode> element it would be much better and efficient to use an <InlineCode>svg</InlineCode> element.

When users draw on screen with their mouses, the mouse event can be easily translated into an <InlineCode>SVGPoint</InlineCode> and then we can assemble theses points to create an <InlineCode>SVGPath</InlineCode>:

```tsx
type SVGPoint = { x: number; y: number }
type SVGPath = {
  id: string
  points: SVGPoint[]
  strokeColor: string
  strokeWidth: number
  ended: boolean
}
```

So our svg canvas will render an array of <InlineCode>SVGPath</InlineCode> by computing the path shape thanks to the array of <InlineCode>SVGPoint</InlineCode> with applying on it a `cubic bezier curve`:

```tsx
const d = points.reduce<string>((d, point, index, points) => {
  return index === 0
    ? `M ${point.x},${point.y}`
    : `${d} ${getCubicBezierCurve(point, index, points, curveSmoothing)}`
}, '')
```

<Callout icon='ðŸ’¡'>
  Curve smoothing is here to help to define the coordinates of the control
  points for the cubic bezier curve
</Callout>

And our svg canvas can just expose in the end an <InlineCode>onChange</InlineCode> prop to let parent components to apply some logic when paths are changing in the canvas:

```tsx
<DrawingCanvas
  ref={canvasRef}
  backgroundColor='transparent'
  width='100%'
  height='100%'
  strokeColor={STROKE_COLOR}
  strokeWidth={STROKE_WIDTH}
  onChange={() => {}}
  pathDisappearingTimeoutMs={PATH_DISAPPEARING_TIMEOUT_MS}
/>
```

Please note I wrote the code of the drawing svg canvas without using any external package but I'm sure there are some better drawing canvas out there.
You can [check out](https://www.aureliendupaysdexemple.com/lab/drawing-editor) the drawing editor on his lab page:

<RoundedVideo src='/medias/mdx-content/drawing-editor.webm' />

You can [check the code](https://github.com/SugarDarius/aureliendupaysdexemple/blob/main/components/lab/drawing-editor.tsx) on GitHub ðŸ™‚

## Broadcasting events for real-time collaboration

Thanks to the exposed <InlineCode>onChange</InlineCode> prop on the drawing we can simply broadcast events using the <InlineCode>useBroadcastEvent</InlineCode> hook exported from the Liveblocks config.

Let's start by adding a new room event in our <InlineCode>liveblocks.config.ts</InlineCode> file:

```ts
import type { SVGPath } from './components/lab/drawing-canvas/svg-canvas-path'

type RoomEvent = {
  type: 'ADD_SVG_PATHS'
  paths: SVGPath[]
}

declare global {
  interface Liveblocks {
    RoomEvent: RoomEvent
  }
}
```

After having wrapped the drawing on screen editor with <InlineCode>RoomProvider</InlineCode> component you can call the <InlineCode>useBroadcastEvent</InlineCode> React hook to broadcast events:

```tsx
import { useBroadcastEvent } from '@liveblocks/react/suspense'
import {
  type DrawingCanvasRef,
  DrawingCanvas,
} from '@/components/lab/drawing-canvas/drawing-canvas'

function DrawingOnScreenEditor() {
  /** @type DrawingCanvasRef */
  const canvasRef = useRef(null)
  const broadcast = useBroadcastEvent()

  const handleCanvasChange = useEvent((paths: SVGPath[]): void => {
    broadcast({
      type: 'ADD_SVG_PATHS',
      paths,
    })
  })

  return (
    <DrawingCanvas
      ref={canvasRef}
      backgroundColor='transparent'
      width='100%'
      height='100%'
      strokeColor={STROKE_COLOR}
      strokeWidth={STROKE_WIDTH}
      onChange={handleCanvasChange}
      pathDisappearingTimeoutMs={PATH_DISAPPEARING_TIMEOUT_MS}
    />
  )
}
```

## Listening on broadcasted events

Once the events are broadcasted we can listen on them using the <InlineCode>useEventListener</InlineCode> React hook an sync the paths:

```tsx
import { useEventListener } from '@liveblocks/react/suspense'
import type {
  DrawingCanvasRef,
  DrawingCanvas,
} from '@/components/lab/drawing-canvas/drawing-canvas'

function DrawingOnScreenEditor() {
  /** @type DrawingCanvasRef */
  const canvasRef = useRef(null)

  const handleCanvasChange = useEvent((): void => {
    /* ... */
  })

  useEventListener(({ event }): void => {
    if (canvasRef.current && event.type === 'ADD_SVG_PATHS') {
      // NOTE: `canvasRef` is an imperative handle to allow
      // to do operations using a custom handle exposed as ref.
      // It simplify the need to sync paths in the drawing canvas when
      // listening on events
      canvasRef.current.sync(event.paths)
    }
  })

  return (
    <DrawingCanvas
      ref={canvasRef}
      backgroundColor='transparent'
      width='100%'
      height='100%'
      strokeColor={STROKE_COLOR}
      strokeWidth={STROKE_WIDTH}
      onChange={handleCanvasChange}
      pathDisappearingTimeoutMs={PATH_DISAPPEARING_TIMEOUT_MS}
    />
  )
}
```

And here we go ðŸš€ we can now broadcast and listen on events to draw on screen ðŸ™‚

## Demo

<RoundedVideo src='/medias/mdx-content/liveblocks-drawing-on-screen.webm' />

[Check out](https://www.aureliendupaysdexemple.com/lab/liveblocks-drawing-on-screen) the Liveblocks drawing on screen experiment on his lab page.

## Conclusion

Thanks to **Liveblocks** as a developer we don't have to care all about the stuff on broadcasting and listening events. It's simple with a few lines of code ðŸš€.

**Liveblocks** allows to bring collaboration with a fast pace on your product and this is amazing ðŸ˜ƒ.
No more headaches about how to design the infrastructure nor create the code to handle websocket in your frontend app with a good level of abstraction.
You can just focus on what's matter the most to bring a super user experience to your customers in your product.
And this feels really good ðŸ˜Š

<hr />

### Additional notes

This experiment is using **Liveblocks 2.0**. [Check out](https://liveblocks.io/docs/platform/upgrading/2.0) the upgrading guide if you're coming from the first version as there are a lot of breaking changes.

This experiment is very straightforward and focus on the main collaborative side logic. Still their is room for improvements like performances when syncing the paths in the drawing canvas.
