---
title: 'Liveblocks drawing on screen'
publishedAt: '2024-06-24'
summary: 'An experiment with Liveblocks broadcasted events to draw on screen'
category: 'Lab / Open Source'
githubURL: 'https://github.com/SugarDarius/aureliendupaysdexemple/blob/main/components/lab/drawing-on-screen-editor.tsx'
image: '/medias/mdx-content/liveblocks-drawing-on-screen.webp'
---

<Callout icon='⚠️'>Under construction</Callout>

# An experiment to draw on screen

This experiment comes from my use of Slack Huddle when someone was sharing his screen and we were drawing on it with a pen tool.

I wanted to re-create it using a great collaborative tool to do it.
So I chosen to use [Liveblocks](https://liveblocks.io/) and implement it on my personal website as a Lab 🙂.

## Why drawing on screen?

Drawing on screen is to me a great feature. It brings value and accessibility to users especially when share a screen in an application.
It makes easier to communicate and express yourself when your pointing something present in the shared screen.

From a collaborative standpoint, drawing on screen in real-time brings some great benefits such as:

- Enhanced communication
- Improved collaboration
- Users engagement
- Visual clarity
- Real-time feedback
- Interactive learning
- Memory aid

Having this feature in your product when you let users sharing their screen to each others make the collaborative side more stronger.

## Let's talk about Liveblocks

[Liveblocks](https://liveblocks.io/) is for me a great product providing a complete toolkit to developers to integrate collaborative experiences seamlessly with pace.

Benefits of using **Liveblocks** as developers are you can integrates with your frontend framework while Liveblocks is managing all the infrastructure and scaling for you.
As a developer deeply believing in frontend cloud it's for me a good match.

Adding **Liveblocks** into your project is very straightforward.
First you need to create an account on the web app and then you install the packages you need in your app.
In my case on my personal website:

```sh
$ npm i @liveblocks/client @liveblocks/react
```

Once you've installed the dependencies you can now create config file with your public key created on the **Liveblocks** dashboard:

```tsx
import { createClient } from '@liveblocks/client'
import { createRoomContext } from '@liveblocks/react'

const client = createClient({
  publicApiKey: 'your_liveblocks_public_key',
})

type Presence = {}
type Storage = {}
type UserMeta = {}
type RoomEvent = {}

export const {
  suspense: { RoomProvider, useBroadcastEvent, useEventListener },
} = createRoomContext<Presence, Storage, UserMeta, RoomEvent>(client)
```

And you're good to go 🚀

## Drawing paths on screen with an svg canvas

Drawing on screen when sharing screen should stay simple and light in my opinion.
So I though that instead of using a <InlineCode>canvas</InlineCode> element it would be much better and efficient to use an <InlineCode>svg</InlineCode> element.

When users draw on screen with their mouses, the mouse event can be easily translated into an <InlineCode>SVGPoint</InlineCode> and then assembly theses points to create an <InlineCode>SVGPath</InlineCode>:

```tsx
type SVGPoint = { x: number; y: number }
type SVGPath = {
  id: string
  points: SVGPoint[]
  strokeColor: string
  strokeWidth: number
  ended: boolean
}
```

So our svg canvas will render an array of <InlineCode>SVGPath</InlineCode> by computing the path shape thanks to the array of <InlineCode>SVGPoint</InlineCode> with applying on it a `cubic bezier curve`:

```tsx
const d = points.reduce<string>((d, point, index, points) => {
  return index === 0
    ? `M ${point.x},${point.y}`
    : `${d} ${getCubicBezierCurve(point, index, points, curveSmoothing)}`
}, '')
```

<Callout icon='💡'>
  Curve smoothing is here to help to define the coordinates of the control
  points for the cubic bezier curve
</Callout>

And our svg canvas can just expose in the end an <InlineCode>onChange</InlineCode> prop to let parent components to apply some logic when paths are changing in the canvas:

```tsx
<DrawingCanvas
  ref={canvasRef}
  backgroundColor='transparent'
  className='absolute left-0 top-0'
  width='100%'
  height='100%'
  strokeColor={STROKE_COLOR}
  strokeWidth={STROKE_WIDTH}
  onChange={handleCanvasChange}
  pathDisappearingTimeoutMs={PATH_DISAPPEARING_TIMEOUT_MS}
/>
```

Please note I wrote the code of the drawing svg canvas without using any external package but I'm sure there are some better drawing canvas out there.
You can [check out](https://www.aureliendupaysdexemple.com/lab/drawing-editor) the drawing editor on his lab page:

<RoundedVideo src='/medias/mdx-content/drawing-editor.webm' />

And [check the code](https://github.com/SugarDarius/aureliendupaysdexemple/blob/main/components/lab/drawing-editor.tsx) on GitHub 🙂

## Broadcasting events for real-time collaboration

Thanks to the exposed <InlineCode>onChange</InlineCode> prop on the drawing we can simply broadcast events using the <InlineCode>useBroadcastEvent</InlineCode> hook exported from the Liveblocks config.

Let's start by adding a new room event in our config:

```ts
import type { SVGPath } from '@/components/lab/drawing-canvas/svg-canvas-path'

// liveblocks.config.ts
type RoomEvent = {
  type: 'ADD_SVG_PATHS'
  paths: SVGPath[]
}
```

After having wrapped the drawing on screen editor with <InlineCode>RoomProvider</InlineCode> you can call the <InlineCode>useBroadcastEvent</InlineCode> React hook to broadcast events:

```tsx
import { useBroadcastEvent } from '@/liveblocks.config'
import type {
  DrawingCanvasRef,
  DrawingCanvas,
} from '@/components/lab/drawing-canvas/drawing-canvas'

function DrawingOnScreenEditor() {
  /** @type DrawingCanvasRef */
  const canvasRef = useRef(null)
  const broadcast = useBroadcastEvent()

  const handleCanvasChange = useEvent(
    (
      paths: SVGPath[],
      // Note: options to keep it clean
      // and to avoid infinite loop when syncing paths
      { isFromSyncOperation, isFromDisappearOperation }
    ): void => {
      if (!isFromSyncOperation && !isFromDisappearOperation) {
        broadcast({
          type: 'ADD_SVG_PATHS',
          paths,
        })
      }
    }
  )

  return (
    <DrawingCanvas
      ref={canvasRef}
      backgroundColor='transparent'
      className='absolute left-0 top-0'
      width='100%'
      height='100%'
      strokeColor={STROKE_COLOR}
      strokeWidth={STROKE_WIDTH}
      onChange={handleCanvasChange}
      pathDisappearingTimeoutMs={PATH_DISAPPEARING_TIMEOUT_MS}
    />
  )
}
```

## Listening on broadcasted events

Once the events are broadcasted we can listen on them using the <InlineCode>useEventListener</InlineCode> React hook an sync the paths:

```tsx
import { useEventListener } from '@/liveblocks.config'
import type {
  DrawingCanvasRef,
  DrawingCanvas,
} from '@/components/lab/drawing-canvas/drawing-canvas'

function DrawingOnScreenEditor() {
  /** @type DrawingCanvasRef */
  const canvasRef = useRef(null)

  const handleCanvasChange = useEvent((): void => {
    /* ... */
  })

  useEventListener(({ event }): void => {
    if (canvasRef.current && event.type === 'ADD_SVG_PATHS') {
      // NOTE: `canvasRef` is an imperative handle to allow
      // to do operations using a custom handle exposed as ref.
      // It simplify the need to sync paths in the drawing canvas when
      // listening on events
      canvasRef.current.sync(event.paths)
    }
  })

  return (
    <DrawingCanvas
      ref={canvasRef}
      backgroundColor='transparent'
      className='absolute left-0 top-0'
      width='100%'
      height='100%'
      strokeColor={STROKE_COLOR}
      strokeWidth={STROKE_WIDTH}
      onChange={handleCanvasChange}
      pathDisappearingTimeoutMs={PATH_DISAPPEARING_TIMEOUT_MS}
    />
  )
}
```

And here we go 🚀
